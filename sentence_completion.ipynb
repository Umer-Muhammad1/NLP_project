{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a98995ee357a466e9fcdeb32423ce216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_275841376d12499fa412cd489c6a1d9e",
              "IPY_MODEL_5c56e138efbf4b9aa398ab0149713a6e",
              "IPY_MODEL_bef29f18e88a4418a4c4097df923ab39"
            ],
            "layout": "IPY_MODEL_4b438c4dd83b4d789a6c7000e335c863"
          }
        },
        "275841376d12499fa412cd489c6a1d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_562acb7d4dba41e687ca99f5e7fd5e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_4f32f766658b424a85a399fef65d0a89",
            "value": "Processing dataset (num_proc=4): 100%"
          }
        },
        "5c56e138efbf4b9aa398ab0149713a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a85301c355c944369f6cce39b68c4816",
            "max": 52002,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72f7cb3ba18b48ffb47a45350d1f2168",
            "value": 52002
          }
        },
        "bef29f18e88a4418a4c4097df923ab39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdfa33c52e674cda8d3aa0f262b96874",
            "placeholder": "​",
            "style": "IPY_MODEL_b3a774ef13f84e1ab7870fafe826eef9",
            "value": " 52002/52002 [01:14&lt;00:00, 436.07 examples/s]"
          }
        },
        "4b438c4dd83b4d789a6c7000e335c863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562acb7d4dba41e687ca99f5e7fd5e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f32f766658b424a85a399fef65d0a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a85301c355c944369f6cce39b68c4816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f7cb3ba18b48ffb47a45350d1f2168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdfa33c52e674cda8d3aa0f262b96874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a774ef13f84e1ab7870fafe826eef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ium_lnH8M8oH",
        "outputId": "6384912f-cd22-490f-9014-41cb007399fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
        "from datasets import load_dataset\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from torch.utils.data import DataLoader\n",
        "import os"
      ],
      "metadata": {
        "id": "Bo9e7z4fM9jl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSyOmD_7M9hz",
        "outputId": "a6f32df8-7b5f-4b3c-e2e1-5588be318cf6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIqJZL5OM9fW",
        "outputId": "663bcc09-29cc-4d4a-8beb-a1807e76ac4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    model.config.pad_token_id = model.config.eos_token_id"
      ],
      "metadata": {
        "id": "X5weJJgbOROS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"tatsu-lab/alpaca\")\n",
        "print(f\"Dataset loaded with {len(dataset['train'])} training examples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pol6ZUqyOVJt",
        "outputId": "74811b7b-dc4a-4724-ca41-46f07079dfdc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded with 52002 training examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_training_example(example, max_length=512):\n",
        "    \"\"\"\n",
        "    Prepares a dataset example for instruction fine-tuning by tokenizing and\n",
        "    properly formatting inputs and labels.\n",
        "\n",
        "    Args:\n",
        "        example (dict): Dictionary containing 'instruction', 'input', and 'output' keys\n",
        "        max_length (int): Maximum sequence length\n",
        "\n",
        "    Returns:\n",
        "        dict: Processed example with input_ids, attention_mask, and labels\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Format the prompt and full text\n",
        "        if example['input']:\n",
        "            prompt = f\"Instruction: {example['instruction']}\\nInput: {example['input']}\\nOutput:\"\n",
        "        else:\n",
        "            # Handle cases where input is empty\n",
        "            prompt = f\"Instruction: {example['instruction']}\\nOutput:\"\n",
        "\n",
        "        full_text = prompt + \" \" + example[\"output\"]\n",
        "\n",
        "        # Tokenize the full sequence\n",
        "        tokenized = tokenizer(\n",
        "            full_text,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            padding=\"max_length\",\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "\n",
        "        # Tokenize just the prompt to find its length\n",
        "        prompt_tokens = tokenizer(\n",
        "            prompt,\n",
        "            add_special_tokens=False\n",
        "        )\n",
        "\n",
        "        # Set up labels: -100 for prompt tokens (to be ignored by loss function)\n",
        "        labels = tokenized[\"input_ids\"].copy()\n",
        "        prompt_length = len(prompt_tokens[\"input_ids\"])\n",
        "\n",
        "        # Set prompt tokens to -100 so they're ignored in loss calculation\n",
        "        for i in range(prompt_length):\n",
        "            if i < len(labels):\n",
        "                labels[i] = -100\n",
        "\n",
        "        # Also mask padding tokens in the labels\n",
        "        for i in range(len(labels)):\n",
        "            if tokenized[\"attention_mask\"][i] == 0:  # This is a padding token\n",
        "                labels[i] = -100\n",
        "\n",
        "        tokenized[\"labels\"] = labels\n",
        "        return tokenized\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing example: {e}\")\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": [tokenizer.pad_token_id] * 2,\n",
        "            \"attention_mask\": [0] * 2,\n",
        "            \"labels\": [-100] * 2\n",
        "        }"
      ],
      "metadata": {
        "id": "mJA37xzlM9cz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512  # Adjust based on your needs and GPU memory\n",
        "processed_dataset = dataset.map(\n",
        "    lambda x: prepare_training_example(x, max_length=max_length),\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    desc=\"Processing dataset\",\n",
        "    num_proc=4\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a98995ee357a466e9fcdeb32423ce216",
            "275841376d12499fa412cd489c6a1d9e",
            "5c56e138efbf4b9aa398ab0149713a6e",
            "bef29f18e88a4418a4c4097df923ab39",
            "4b438c4dd83b4d789a6c7000e335c863",
            "562acb7d4dba41e687ca99f5e7fd5e9c",
            "4f32f766658b424a85a399fef65d0a89",
            "a85301c355c944369f6cce39b68c4816",
            "72f7cb3ba18b48ffb47a45350d1f2168",
            "cdfa33c52e674cda8d3aa0f262b96874",
            "b3a774ef13f84e1ab7870fafe826eef9"
          ]
        },
        "id": "RLUkB4T_M9Z_",
        "outputId": "aa04f169-1219-4732-8285-64ba0e575503"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing dataset (num_proc=4):   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a98995ee357a466e9fcdeb32423ce216"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, tokenizer, test_examples, device=\"cuda\", max_new_tokens=100):\n",
        "    \"\"\"\n",
        "    Evaluates a model on a list of test examples.\n",
        "\n",
        "    Args:\n",
        "        model: The model to evaluate\n",
        "        tokenizer: The tokenizer to use\n",
        "        test_examples: List of dictionaries with 'instruction', 'input', and 'reference_output' keys\n",
        "        device: Device to run inference on\n",
        "        max_new_tokens: Maximum number of tokens to generate\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with generated responses and metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    for example in test_examples:\n",
        "        instruction = example['instruction']\n",
        "        input_text = example.get('input', '')\n",
        "        reference = example.get('reference_output', '')\n",
        "\n",
        "        # Format the prompt based on whether input is provided\n",
        "        if input_text:\n",
        "            prompt = f\"Instruction: {instruction}\\nInput: {input_text}\\nOutput:\"\n",
        "        else:\n",
        "            prompt = f\"Instruction: {instruction}\\nOutput:\"\n",
        "\n",
        "        # Tokenize and move to device\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=inputs[\"input_ids\"],\n",
        "                attention_mask=inputs[\"attention_mask\"],\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "            )\n",
        "\n",
        "        # Decode and extract only the response part\n",
        "        full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        response = full_output[len(prompt):].strip()\n",
        "\n",
        "        results.append({\n",
        "            'instruction': instruction,\n",
        "            'input': input_text,\n",
        "            'generated_output': response,\n",
        "            'reference_output': reference\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "e5nQq0K9PVof"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample test examples\n",
        "test_examples = [\n",
        "    {\n",
        "        'instruction': 'Write a short poem',\n",
        "        'input': 'about artificial intelligence',\n",
        "        'reference_output': 'In silicon dreams and neural might,\\nA new mind awakens to the light.\\nNot born of flesh but human thought,\\nIntelligence that we have wrought.'\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Translate the following sentence to German\",\n",
        "        \"input\": \"I am hungry\",\n",
        "        \"reference_output\": \"Ich habe Hunger\"\n",
        "    },\n",
        "    {\n",
        "        'instruction': 'Summarize the main idea',\n",
        "        'input': 'The Internet of Things (IoT) refers to the billions of physical devices around the world that are now connected to the internet, collecting and sharing data.',\n",
        "        'reference_output': 'The Internet of Things (IoT) is a network of billions of internet-connected physical devices worldwide that collect and share data.'\n",
        "    },\n",
        "    {\n",
        "        'instruction': 'Explain the concept of photosynthesis in simple terms',\n",
        "        'input': '',\n",
        "        'reference_output': 'Photosynthesis is how plants make their own food. They use sunlight, water, and carbon dioxide to create energy and oxygen. It\\'s like plants cooking their meals using sunlight as the heat source.'\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "w4ASWsI8Pm0S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run tests and display results\n",
        "def run_model_evaluation(model_name=\"Base Model\", save_results=False):\n",
        "    print(f\"\\n===== {model_name} Evaluation =====\")\n",
        "\n",
        "    model.to(device)\n",
        "    results = evaluate_model(model, tokenizer, test_examples, device)\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"Instruction: {result['instruction']}\")\n",
        "        if result['input']:\n",
        "            print(f\"Input: {result['input']}\")\n",
        "        print(f\"\\nGenerated output: {result['generated_output']}\")\n",
        "        if result['reference_output']:\n",
        "            print(f\"Reference output: {result['reference_output']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    if save_results:\n",
        "        import json\n",
        "        import os\n",
        "        results_dir = \"./evaluation_results\"\n",
        "        os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "        with open(f\"{results_dir}/{model_name.replace(' ', '_').lower()}_results.json\", \"w\") as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        print(f\"Results saved to {results_dir}/{model_name.replace(' ', '_').lower()}_results.json\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "qPiFfLzVPrpV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Test before fine-tuning\n",
        "print(\"\\n\\n=============== BEFORE FINE-TUNING EVALUATION ===============\")\n",
        "before_results = run_model_evaluation(\"Before Fine-tuning\", save_results=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7RlUSHUWYdO",
        "outputId": "ee199619-24a8-4244-d64f-a32c9ce4742f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=============== BEFORE FINE-TUNING EVALUATION ===============\n",
            "\n",
            "===== Before Fine-tuning Evaluation =====\n",
            "\n",
            "Example 1:\n",
            "Instruction: Write a short poem\n",
            "Input: about artificial intelligence\n",
            "\n",
            "Generated output: About artificial intelligence\n",
            "Input: about artificial intelligence\n",
            "Output: About artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: About artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Output: about artificial intelligence\n",
            "Reference output: In silicon dreams and neural might,\n",
            "A new mind awakens to the light.\n",
            "Not born of flesh but human thought,\n",
            "Intelligence that we have wrought.\n",
            "--------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "Instruction: Translate the following sentence to German\n",
            "Input: I am hungry\n",
            "\n",
            "Generated output: You're hungry\n",
            "Input: I'm hungry\n",
            "Output: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Output: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Input: You're hungry\n",
            "Reference output: Ich habe Hunger\n",
            "--------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "Instruction: Summarize the main idea\n",
            "Input: The Internet of Things (IoT) refers to the billions of physical devices around the world that are now connected to the internet, collecting and sharing data.\n",
            "\n",
            "Generated output: The IoT is a set of virtual machines that can be programmed to perform tasks, and they can be used to help the world.\n",
            "One of the big problems with the IoT is that it's not always easy to set up a real world IoT device. For example, if you're going to take your kids to the airport, you might want to set up a real-world IoT device that will be able to connect you to the airport.\n",
            "In this article, we'll\n",
            "Reference output: The Internet of Things (IoT) is a network of billions of internet-connected physical devices worldwide that collect and share data.\n",
            "--------------------------------------------------\n",
            "\n",
            "Example 4:\n",
            "Instruction: Explain the concept of photosynthesis in simple terms\n",
            "\n",
            "Generated output: Use this tool to show the structure of photosynthesis\n",
            "Example:\n",
            "1.3.1.1.2.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.\n",
            "Reference output: Photosynthesis is how plants make their own food. They use sunlight, water, and carbon dioxide to create energy and oxygen. It's like plants cooking their meals using sunlight as the heat source.\n",
            "--------------------------------------------------\n",
            "Results saved to ./evaluation_results/before_fine-tuning_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure LoRA\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],\n",
        "    inference_mode=False\n",
        ")"
      ],
      "metadata": {
        "id": "w-WW9H9fQQcQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare model for LoRA fine-tuning\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgxUM34PQY4_",
        "outputId": "ab5edf6a-84c8-4526-bd7b-79fca66939f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training arguments\n",
        "output_dir = \"./gpt2-alpaca-lora\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=100,\n",
        "    max_steps=1000,  # Adjust based on dataset size and needs\n",
        "    learning_rate=2e-4,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=10,\n",
        "    save_steps=200,\n",
        "    save_total_limit=3,\n",
        "    report_to=\"tensorboard\",\n",
        "    run_name=\"gpt2-alpaca-lora\",\n",
        "    remove_unused_columns=False,\n",
        ")"
      ],
      "metadata": {
        "id": "mV8eYwqaQfCQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Not using masked language modeling\n",
        ")"
      ],
      "metadata": {
        "id": "Syyd6a1DQmz2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iwUHPnaRQqbK",
        "outputId": "414ec67d-fc9c-45bb-a04a-c018cb35cbf9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 324/1000 04:38 < 09:45, 1.16 it/s, Epoch 0.10/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.288000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.288400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.103100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.989000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.805700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.648800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.606100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.646800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.649100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.436900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.508400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.536800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.458600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>2.440300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.397100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.447900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>2.424300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.468000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>2.458700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.448100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.420900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>2.439500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.445400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>2.400200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>2.396700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>2.378200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.379700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.383100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>2.435900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>2.360000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 14:23, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.288000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.288400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.103100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.989000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.805700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.648800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.606100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.646800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.649100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.436900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.508400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.536800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.458600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>2.440300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.397100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.447900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>2.424300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.468000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>2.458700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.448100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.420900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>2.439500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.445400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>2.400200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>2.396700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>2.378200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.379700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.383100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>2.435900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>2.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>2.436600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>2.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.373000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>2.306900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>2.372100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>2.421600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>2.361100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.314700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>2.285200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>2.428800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>2.442000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>2.344100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>2.331700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>2.347100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>2.324000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>2.441400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>2.314300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.343400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>2.335100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>2.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>2.363700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>2.288200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>2.370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>2.307800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>2.398900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>2.353700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>2.267300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.345600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>2.336200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>2.347000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>2.331700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>2.284200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>2.321000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>2.304900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>2.344400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>2.329100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>2.347700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>2.353800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>2.357100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>2.319700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>2.407000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>2.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>2.365500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>2.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>2.296900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>2.291200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>2.378700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.407600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>2.328900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>2.318400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>2.256900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>2.299800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>2.353400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>2.331700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>2.303500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>2.215700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>2.344000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>2.297500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>2.290100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>2.392100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>2.289900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>2.271500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>2.250100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>2.314600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>2.331900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>2.244300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>2.309300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.293000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1000, training_loss=2.4137672634124754, metrics={'train_runtime': 864.7784, 'train_samples_per_second': 18.502, 'train_steps_per_second': 1.156, 'total_flos': 4220535177216000.0, 'train_loss': 2.4137672634124754, 'epoch': 0.30766864087377893})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n=============== AFTER FINE-TUNING EVALUATION ===============\")\n",
        "after_results = run_model_evaluation(\"After Fine-tuning\", save_results=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwiD5dOtSauv",
        "outputId": "bba20195-dbd4-4698-ca19-f72aa99167d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=============== AFTER FINE-TUNING EVALUATION ===============\n",
            "\n",
            "===== After Fine-tuning Evaluation =====\n",
            "\n",
            "Example 1:\n",
            "Instruction: Write a short poem\n",
            "Input: about artificial intelligence\n",
            "\n",
            "Generated output: Artificial intelligence is a technology that allows humans to do tasks more efficiently than humans. It can be used to help solve complex problems and even solve complex problems in a short period of time. AI has also been used to improve the efficiency of business processes, such as hiring and hiring managers, to improve productivity. Artificial intelligence is also used to make decisions more intuitive and more accurate. Artificial intelligence is also used to help automate tasks such as designing software and developing new products. Artificial intelligence is also used to provide\n",
            "Reference output: In silicon dreams and neural might,\n",
            "A new mind awakens to the light.\n",
            "Not born of flesh but human thought,\n",
            "Intelligence that we have wrought.\n",
            "--------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "Instruction: Translate the following sentence to German\n",
            "Input: I am hungry\n",
            "\n",
            "Generated output: I am hungry!\n",
            "\n",
            "I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am hungry! I am\n",
            "Reference output: Ich habe Hunger\n",
            "--------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "Instruction: Summarize the main idea\n",
            "Input: The Internet of Things (IoT) refers to the billions of physical devices around the world that are now connected to the internet, collecting and sharing data.\n",
            "\n",
            "Generated output: IoT is the Internet of Things that is connected to the physical world through wireless, connected devices and sensors. It is a technological revolution that can revolutionize the way we work and interact with the world. It is the future of information management, data storage, and connected devices. It is an exciting and exciting time to be a part of. IoT is a powerful way to make and share information and to empower people to connect and collaborate. It is the future of data sharing and collaboration. It is a\n",
            "Reference output: The Internet of Things (IoT) is a network of billions of internet-connected physical devices worldwide that collect and share data.\n",
            "--------------------------------------------------\n",
            "\n",
            "Example 4:\n",
            "Instruction: Explain the concept of photosynthesis in simple terms\n",
            "\n",
            "Generated output: Photosynthesis is the process by which photosynthesis converts sunlight into carbon dioxide, which is released into the atmosphere. Photosynthesis involves the formation of new photosystems, such as photosynthetic plants, and photosynthetic algae, which convert sunlight into carbon dioxide. Photosynthesis takes place on a cellular level, where plants use the energy from sunlight to grow and produce food. Photosynthesis is also responsible for the formation of new photochemical reactions that allow plants to process carbon dioxide. This process can be\n",
            "Reference output: Photosynthesis is how plants make their own food. They use sunlight, water, and carbon dioxide to create energy and oxygen. It's like plants cooking their meals using sunlight as the heat source.\n",
            "--------------------------------------------------\n",
            "Results saved to ./evaluation_results/after_fine-tuning_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sCWjUZaCSace"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}