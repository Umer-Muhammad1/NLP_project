# language_translation_project
Projet : Aligner GPT-2 pour en faire un assistant (Instruction Tuning)
ğŸ¯ Objectif
Lâ€™objectif de ce projet est de transformer un modÃ¨le de langage standard (GPT-2) en un assistant capable de suivre des instructions. Les Ã©tudiants commenceront par utiliser GPT-2 dans sa forme brute, puis le fine-tuneront Ã  lâ€™aide dâ€™un petit dataset dâ€™instructions (comme OpenAssistant) et dâ€™un apprentissage efficace via LoRA (Low-Rank Adaptation).

ğŸ§‘â€ğŸ¤â€ğŸ§‘ **Travail en groupe**
Groupes de 2 Ã  4 Ã©tudiants
DurÃ©e : 2 semaines
LibertÃ© totale sur le choix du modÃ¨le/dataset (tant que la mÃ©thodologie est respectÃ©e)

ğŸ§©**Ã‰tapes du projet**
1. Chargement et test du modÃ¨le de base
Charger et utiliser GPT-2 (ou un modÃ¨le similaire, ex : DistilGPT2).
GÃ©nÃ©rer du texte avec des prompts simples.

Constater que le modÃ¨le :
Ne suit pas les instructions (ex : "traduire", "rÃ©sumer", "donner un conseil").
Se contente de complÃ©ter une phrase.

3. Choix dâ€™un dataset dâ€™instructions
TÃ©lÃ©charger un petit dataset d'instructions. Exemples :
OpenAssistant (OASST1)
Alpaca
FLAN
PossibilitÃ© de crÃ©er un dataset personnalisÃ© (500 Ã  2 000 exemples suffisent).

5. Fine-tuning avec LoRA (PEFT)
Utiliser les outils Hugging Face : transformers, peft, datasets, etc.
Geler le modÃ¨le de base et entraÃ®ner uniquement les couches LoRA.
Adapter les sÃ©quences (max 128 ou 256 tokens) pour entraÃ®ner rapidement sur GPU (Colab ou autre).
6. Ã‰valuation et comparaison
Faire une conversation avant/aprÃ¨s fine-tuning sur plusieurs types d'instructions.
Comparer qualitativement les rÃ©ponses : pertinence, clartÃ©, utilitÃ©.
(Bonus) Ajouter une interface simple en ligne de commande ou notebook pour tester l'assistant.

**ğŸ“¦ Livrables attendus**
ğŸ“ Code du projet (scripts, notebooks, requirements)
ğŸ§  ModÃ¨le entraÃ®nÃ© (uploadÃ© sur Hugging Face ou sauvegardÃ© localement)
ğŸ“„ Exemples de prompts/rÃ©ponses avant et aprÃ¨s fine-tuning
(Optionnel) Un court rapport expliquant :
Le choix du dataset
La mÃ©thode de fine-tuning
Les limites observÃ©es

**ğŸ› ï¸ Ressources utiles**

Hugging Face Transformers

PEFT / LoRA (HF)

Tutoriel de fine-tuning avec LoRA

Colab avec GPU (si besoin)

**ğŸ’¬ Questions types pour tester le modÃ¨le**
Traduis : "Je vais bien, merci."
RÃ©sume ce texte : ...
Donne-moi une idÃ©e de projet.
Que puis-je faire aujourdâ€™hui ?
Quels sont les avantages du sport ?

**ğŸ¤– Objectif final**
Ã€ la fin du projet, vous aurez :

ExpÃ©rimentÃ© avec un vrai modÃ¨le de langage non alignÃ©.
Appris Ã  le fine-tuner avec LoRA de faÃ§on efficace.
CrÃ©Ã© une version â€œassistanteâ€ capable de suivre des instructions !
